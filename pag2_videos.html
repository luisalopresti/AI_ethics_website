<!DOCTYPE html>
<html>
<head>
    <meta name='viewport' content='with=device-width, initial-scale=1.0'> <!--responsiveness-->
    <title>AI & HUMAN RIGHTS</title>
    <link rel="icon" href="images/logo.png">
    <link rel='stylesheet' href='style.css'>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Montagu+Slab:wght@400;500;600&display=swap" rel="stylesheet">
    <!--add this to use icons-->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>
<body>
    <section class='SubHeader'>
        <nav> <!--major block of navigation link upper right corner--> 
            <a href='index.html'><img src='images/logo.png'></a>
            <div class='nav-links' id='navlinks'>
                <!--close bottom icon-->
                <i class="fa fa-times" onclick='hideMenu()'></i> <!--from https://fontawesome.com/v4.7/icons/ for icons-->
                <ul>
                    <li><a href='index.html'>HOME</a></li>
                    <li><a href='pag2_videos.html'>ETHICS</a></li>
                    <li><a href='bias.html'>BIASES & MINORITIES</a></li>
                    <li><a href='contacts.html'>CONTACTS</a></li>
                </ul>
            </div>
            <!--menu icon-->
            <i class="fa fa-bars" onclick='showMenu()'></i>
        </nav>
        <h1>Fairness and social justice: <br> what are the implications of AI?</h1>
    </section>

    <section class='intro'>
        <h1>Ethics, fairness and social justice</h1>
        <p>In this section, we will take into consideration the risks of AI with respects to minorities,<br>and the necessity to build a legal framework to put some ethical constraints on the use of this technologies.<br>Here, we propose several interesting resources (videos and podcasts).</p>
    </section>

   <!--video section-->
   <section class='ethics-pag'>
       <!--first video-->
       <div class='row'> <!--already css defined, in pag1-->
           <div class='ethics-col'>
               <h1>The Social Implications of Machine Learning</h1>
                <p>
                    This 13 minutes video, produced by <b>Dow Jones & Company</b> (New York, NY: <b>Wall Street Journal</b>, 2019), analyses the biases of AI. <br> We expect Artificial Intelligence to have great performances, to be unbiased, and to solve our issues in a way we could not figure out, but AI is trained with our data, and data are biased. <br> Data are a picture of the society we are in, and a biased society can only lead to a biased AI. <br> This short video explains in a clear and simple way this <i>tech-washing</i> and the <i>automation bias phenomena</i>. The speaker also focuses on the lack of diversity and the necessity to address this issue and to build an accountability system inside the tech industry.
                </p>
            </div>

           <div class='ethics-col-vid'> 
            <iframe width="560" height="315" src="https://video.alexanderstreet.com/watch/the-social-implications-of-machine-learning" frameborder="0" allowfullscreen>
            </iframe>
           </div>
       </div>

       <!--second video-->
       <div class='row'> <!--already css defined, in pag1-->
        <div class='ethics-col-vid2'> 
         <iframe width="560" height="315" src="https://video.alexanderstreet.com/watch/are-you-scared-yet-human" frameborder="0" allowfullscreen>
         </iframe>
        </div>

        <div class='ethics-col'>
            <h1>Are You Scared Human, Yet?</h1>
             <p>
                This <b>BBC documentary</b> (2021) deals with the issue of lack of accountability and regulation, on a national and international level, concerning AI. <br> AI is capable to do great things, but may also be dangerous and prone to be used for malitious goals. <br> In recent years, it became clear that the country that lead in AI would enjoy great economic benefits for decades, and China and the US seems to be in a war to impose themselves as the global leader. <br>
                The stakes are high: whoever wins this technology race will be able to dictate the regulatory framework and set the value system for the whole world! <br>
                Several issues can be raised: in China, in particular in the Xinjiang region, AI applications seems to be more than concerning.
                Among others, AI is also used to detect possible criminals, terrorists, or separatists, basing its decisions on the emotional state of the subject, which is likely to be altered given the situation they are exposed to. Thus, AI is used to confirm authority's prejudices without real evidence.<br>
                The military is another industry that is giving much importance to AI: in the US, several autonomous and AI based weapons are being introduced.
                Particularly advanced arm systems, with the dimensions of a mosquito, have been developed: they are able to fly, reach the targeted person, and to explode as a bullet.<br>
                Given this framework, the head of the United Nations is urging the superpowers to work together on AI, under the plausible fear that the AI arms race could lead to a conflict between China and the US. <br>
                It seems clear that the AI topic is becoming more and more a geo-strategic, geo-politic, and militar issue, and experts seem to fear an outcome resambling to George Orwell's book <i>1984</i>.
             </p>
         </div>
    </div>
   </section>

   <!--podcasts-->
   <section class='podcast'> 
    <h1>Podcasts</h1>
    <div class='row'>
        <div class='podcast-col'>
            <img src='images/oecd.jpg'>
            <div class='layer'>
                <a href='https://open.spotify.com/episode/1PTERwZyLw76vjsYTqoJrr?si=SZGT-mavTVeFjGHBGM2Qbg' target="_blank" rel="noopener noreferrer"><h3>Keep control over AI<br>(ep. 1/3)</h3> </a>
            </div>
        </div>
        <div class='podcast-col'>
            <img src='images/thehearing.jfif'>
            <div class='layer'>
                <a href='https://podcasts.apple.com/gb/podcast/ep-77-impact-ai-algorithms-on-fairness-our-justice/id1389813956?i=1000521993015' target="_blank" rel="noopener noreferrer"><h3>The impact of AI on our justice systems</h3></a>
            </div>
        </div>
        <div class='podcast-col'>
            <img src='images/deepmind.jfif'>
            <div class='layer'>
                <a href='https://open.spotify.com/episode/4oSrxUN44Jgfb2wFHc4OK2?si=5b073829e258412b&nd=1' target="_blank" rel="noopener noreferrer"><h3>AI for everyone</h3></a>
            </div>
        </div>
    </div>
   </section>

   <!--footer-->
   <section class='footer'>
       <h4>credits</h4>
       <p>The content of this website has been elaborated in the context of the seminar and workshop of <i>"Artificial Intelligence and Human Rights"</i>, <br>held at the Department of Sociology and Social Research - University of Trento (2021/2022).</p>
       <p>Designed and written by Luisa Lo Presti</p>
       <!--social media links-->
       <div class='icons'>
        <a href='https://www.linkedin.com/in/luisa-lo-presti-629747213/'><i class='fa fa-linkedin'></i></a>
        <a href='https://github.com/luisalopresti'><i class="fa fa-github" aria-hidden="true"></i></a>
       </div>
   </section>


<!--JavaScript-->
<script>
    /* JavaScript to open & close the drop down menu on mobiles*/
    var navlinks = document.getElementById('navlinks');
    function showMenu() {
        navlinks.style.right = '0';
    }
    function hideMenu() {
        navlinks.style.right = '-200px';
    }
</script>
</body>
</html>